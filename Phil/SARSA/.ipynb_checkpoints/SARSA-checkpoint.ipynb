{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_action(q, state):\n",
    "    values = np.array([q[state, a]for a in range(2)])\n",
    "    action = np.argmax(values)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pole_theta_space = np.linspace(-0.20943951, 0.20943951, 10)\n",
    "pole_theta_vel_space = np.linspace(-4, 4, 10)\n",
    "cart_pos_space = np.linspace(-2.5, 2.4, 10)\n",
    "cart_vel_space = np.linspace(-4, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(observation):\n",
    "    cart_x, cart_x_dot, cart_theta, cart_theta_dot = observation\n",
    "    cart_x = int(np.digitize(cart_x, cart_pos_space))\n",
    "    cart_x_dot = int(np.digitize(cart_x_dot, cart_vel_space))\n",
    "    cart_theta = int(np.digitize(cart_theta, pole_theta_space))\n",
    "    cart_theta_dot = int(np.digitize(cart_theta_dot, pole_theta_vel_space))\n",
    "    return (cart_x, cart_x_dot, cart_theta, cart_theta_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_running_average(totalrewards):\n",
    "    N = len(totalrewards)\n",
    "    running_avg = np.empty(N)\n",
    "    for t in range(N):\n",
    "       running_avg[t] = np.mean(totalrewards[max(0, t-100):(t+1)])\n",
    "    plt.plot(running_avg)\n",
    "    plt.title(\"Running Average\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting game  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\apps\\Anaconda3\\envs\\OpenAiGym\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pole_theta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-34bb5ec2b889>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'starting game '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mrand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrand\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-cc7f77ec4b6a>\u001b[0m in \u001b[0;36mget_state\u001b[1;34m(observation)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcart_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigitize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcart_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcart_pos_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcart_x_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigitize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcart_x_dot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcart_vel_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcart_theta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigitize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpole_theta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpole_theta_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mcart_theta_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigitize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpole_theta_dot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpole_theta_vel_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcart_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcart_x_dot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcart_theta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcart_theta_dot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pole_theta' is not defined"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "eps = 1.0\n",
    "\n",
    "states = []\n",
    "for i in range(len(cart_pos_space) + 1):\n",
    "    for j in range(len(cart_vel_space) + 1):\n",
    "        for k in range(len(pole_theta_space) + 1):\n",
    "            for l in range(len(pole_theta_vel_space) + 1):\n",
    "                states.append((i,j,k,l))\n",
    "                \n",
    "q = {}\n",
    "for s in states:\n",
    "    for a in range(2):\n",
    "        q[s, a] = 0\n",
    "        \n",
    "num_games = 50000\n",
    "total_rewards = np.zeros(num_games)\n",
    "\n",
    "for i in range(num_games):\n",
    "    if i % 5000 == 0:\n",
    "        print('starting game ', i)\n",
    "    observation = env.reset()\n",
    "    s = get_state(observation)\n",
    "    rand = np.random.random()\n",
    "    a = max_action(q, s) if rand < (1-eps) else env.actions_space.sample()\n",
    "    done = False\n",
    "    ep_rewards = 0\n",
    "    while not done:\n",
    "        observation_, reward, done, info = env.step(a)\n",
    "        s_ = get_state(observation_)\n",
    "        rand = np.random.random()\n",
    "        a_ = max_actions(q, s_) if rand < (1-eps) else env.action_space.sample()\n",
    "        ep_rewards += reward\n",
    "        q[s, a] += alpha * (reward + gamma*q[s_, a_] - q[s,a])\n",
    "        s, a = s_, a_\n",
    "    eps -= 2/numgames if eps > 0 else 0\n",
    "    total_rewards[i] = ep_rewards\n",
    " \n",
    "plot_running_average(total_rewards)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
